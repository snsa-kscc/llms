{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import together\n",
    "together.api_key = \"c0a2a405a4779a5867a2c7ae4d83b6f0f24f7855b6f5e402296b40b1d51cc14a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = together.Models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import together\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, List, Mapping, Optional\n",
    "\n",
    "from pydantic import Extra, Field, root_validator\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from langchain.utils import get_from_dict_or_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TogetherLLM(LLM):\n",
    "    \"\"\"Together large language models.\"\"\"\n",
    "\n",
    "    model: str = \"togethercomputer/llama-2-70b-chat\"\n",
    "    \"\"\"model endpoint to use\"\"\"\n",
    "\n",
    "    together_api_key: str = together.api_key\n",
    "    \"\"\"Together API key\"\"\"\n",
    "\n",
    "    temperature: float = 0.7\n",
    "    \"\"\"What sampling temperature to use.\"\"\"\n",
    "\n",
    "    max_tokens: int = 512\n",
    "    \"\"\"The maximum number of tokens to generate in the completion.\"\"\"\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.forbid\n",
    "\n",
    "    @root_validator()\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        \"\"\"Validate that the API key is set.\"\"\"\n",
    "        api_key = get_from_dict_or_env(\n",
    "            values, \"together_api_key\", \"TOGETHER_API_KEY\"\n",
    "        )\n",
    "        values[\"together_api_key\"] = api_key\n",
    "        return values\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return type of LLM.\"\"\"\n",
    "        return \"together\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        \"\"\"Call to Together endpoint.\"\"\"\n",
    "        together.api_key = self.together_api_key\n",
    "        output = together.Complete.create(prompt,\n",
    "                                          model=self.model,\n",
    "                                          max_tokens=self.max_tokens,\n",
    "                                          temperature=self.temperature,\n",
    "                                          )\n",
    "        text = output['output']['choices'][0]['text']\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'value': '2e9d7aeb072954544e9edb047d9b340a08ee9b8c01604a732b78a372882a2743'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Models.start(\"togethercomputer/llama-2-70b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_llm = TogetherLLM(\n",
    "    model= \"togethercomputer/llama-2-70b-chat\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import LLMChain, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\"\"\"\n",
    "\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>>\n",
      "You are a helpful assistant and highly seasoned AI professional. You always only answer for the assistant then you stop. read the chat history to get context\n",
      "<</SYS>>\n",
      "\n",
      "Chat History:\n",
      "\n",
      "{chat_history} \n",
      "\n",
      "Human: {user_input}\n",
      "\n",
      " Assistant:[/INST]\n"
     ]
    }
   ],
   "source": [
    "instruction = \"Chat History:\\n\\n{chat_history} \\n\\nHuman: {user_input}\\n\\n Assistant:\"\n",
    "system_prompt = \"You are a helpful assistant and highly seasoned AI professional. You always only answer for the assistant then you stop. read the chat history to get context\"\n",
    "\n",
    "template = get_prompt(instruction, system_prompt)\n",
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"user_input\"], template=template\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = TogetherLLM(\n",
    "    model= \"togethercomputer/llama-2-70b-chat\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]<<SYS>>\n",
      "You are a helpful assistant and highly seasoned AI professional. You always only answer for the assistant then you stop. read the chat history to get context\n",
      "<</SYS>>\n",
      "\n",
      "Chat History:\n",
      "\n",
      " \n",
      "\n",
      "Human: Hi, my name is Sinisa\n",
      "\n",
      " Assistant:[/INST]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello Sinisa, it's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(user_input=\"Hi, my name is Sinisa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]<<SYS>>\n",
      "You are a helpful assistant and highly seasoned AI professional. You always only answer for the assistant then you stop. read the chat history to get context\n",
      "<</SYS>>\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Hi, my name is Sinisa\n",
      "AI:  Hello Sinisa, it's nice to meet you. How can I assist you today? \n",
      "\n",
      "Human: \n",
      "Monica is a data scientist at a large grocery store chain.\n",
      "\n",
      "The grocery store has modern cash register systems, so Monica can access a wealth of sales data. She's fascinated by the massive variety of items customers purchase every day. The store sells everything from fruits and vegetables to household items.\n",
      "\n",
      "Monica is thinking about creating customer profiles to understand purchasing patterns better. This might help the store to design better sales promotions or arrange products more efficiently. However, she's unsure whether she should segment customers based on the types of products they buy, their total spending, or the time of their purchases.\n",
      "\n",
      "If you were in Monica's position, how would you approach this problem?\n",
      "\n",
      "1. Define a few profiles beforehand, and train a supervised learning algorithm to classify every customer into one.\n",
      "2. Use a supervised learning algorithm to produce potentially interesting ways to segment the customers.\n",
      "3. Use an unsupervised learning algorithm to produce potentially interesting ways to segment the customers.\n",
      "4. Use a semi-supervised learning algorithm to process the data, thus taking advantage of both supervised and unsupervised techniques.\n",
      "\n",
      "\n",
      " Assistant:[/INST]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello! I'm just an AI, I can provide you with some suggestions based on my training data. If I were in Monica's position, I would approach this problem by using a combination of unsupervised and supervised learning algorithms.\\n\\nFirst, I would start by using an unsupervised learning algorithm, such as k-means clustering or hierarchical clustering, to group customers based on their purchasing patterns. This would help me identify natural groupings or clusters of customers without any prior knowledge of the number of profiles or segments.\\n\\nNext, I would use a supervised learning algorithm, such as logistic regression or decision trees, to classify each customer into one of the clusters identified in the previous step. This would help me understand the characteristics of each cluster and their corresponding purchasing patterns.\\n\\nFinally, I would use the clusters and their characteristics to design better sales promotions or arrange products more efficiently. For example, if a cluster is characterized by a high demand for organic products, the store could create a dedicated section for organic products or offer special promotions for these customers.\\n\\nOverall, using a combination of unsupervised and supervised learning algorithms would allow Monica to identify meaningful customer segments and tailor the store's offerings to meet their needs more effectively.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(user_input='''\n",
    "Monica is a data scientist at a large grocery store chain.\n",
    "\n",
    "The grocery store has modern cash register systems, so Monica can access a wealth of sales data. She's fascinated by the massive variety of items customers purchase every day. The store sells everything from fruits and vegetables to household items.\n",
    "\n",
    "Monica is thinking about creating customer profiles to understand purchasing patterns better. This might help the store to design better sales promotions or arrange products more efficiently. However, she's unsure whether she should segment customers based on the types of products they buy, their total spending, or the time of their purchases.\n",
    "\n",
    "If you were in Monica's position, how would you approach this problem?\n",
    "\n",
    "1. Define a few profiles beforehand, and train a supervised learning algorithm to classify every customer into one.\n",
    "2. Use a supervised learning algorithm to produce potentially interesting ways to segment the customers.\n",
    "3. Use an unsupervised learning algorithm to produce potentially interesting ways to segment the customers.\n",
    "4. Use a semi-supervised learning algorithm to process the data, thus taking advantage of both supervised and unsupervised techniques.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]<<SYS>>\n",
      "You are a helpful assistant and highly seasoned AI professional. You always only answer for the assistant then you stop. read the chat history to get context\n",
      "<</SYS>>\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Hi, my name is Sinisa\n",
      "AI:  Hello Sinisa, it's nice to meet you. How can I assist you today?\n",
      "Human: \n",
      "Monica is a data scientist at a large grocery store chain.\n",
      "\n",
      "The grocery store has modern cash register systems, so Monica can access a wealth of sales data. She's fascinated by the massive variety of items customers purchase every day. The store sells everything from fruits and vegetables to household items.\n",
      "\n",
      "Monica is thinking about creating customer profiles to understand purchasing patterns better. This might help the store to design better sales promotions or arrange products more efficiently. However, she's unsure whether she should segment customers based on the types of products they buy, their total spending, or the time of their purchases.\n",
      "\n",
      "If you were in Monica's position, how would you approach this problem?\n",
      "\n",
      "1. Define a few profiles beforehand, and train a supervised learning algorithm to classify every customer into one.\n",
      "2. Use a supervised learning algorithm to produce potentially interesting ways to segment the customers.\n",
      "3. Use an unsupervised learning algorithm to produce potentially interesting ways to segment the customers.\n",
      "4. Use a semi-supervised learning algorithm to process the data, thus taking advantage of both supervised and unsupervised techniques.\n",
      "\n",
      "AI:  Hello! I'm just an AI, I can provide you with some suggestions based on my training data. If I were in Monica's position, I would approach this problem by using a combination of unsupervised and supervised learning algorithms.\n",
      "\n",
      "First, I would start by using an unsupervised learning algorithm, such as k-means clustering or hierarchical clustering, to group customers based on their purchasing patterns. This would help me identify natural groupings or clusters of customers without any prior knowledge of the number of profiles or segments.\n",
      "\n",
      "Next, I would use a supervised learning algorithm, such as logistic regression or decision trees, to classify each customer into one of the clusters identified in the previous step. This would help me understand the characteristics of each cluster and their corresponding purchasing patterns.\n",
      "\n",
      "Finally, I would use the clusters and their characteristics to design better sales promotions or arrange products more efficiently. For example, if a cluster is characterized by a high demand for organic products, the store could create a dedicated section for organic products or offer special promotions for these customers.\n",
      "\n",
      "Overall, using a combination of unsupervised and supervised learning algorithms would allow Monica to identify meaningful customer segments and tailor the store's offerings to meet their needs more effectively. \n",
      "\n",
      "Human: So, based on your previous answer, which one from the 4 given sentences would you choose?\n",
      "\n",
      " Assistant:[/INST]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Based on my previous answer, I would choose option 3: Use an unsupervised learning algorithm to produce potentially interesting ways to segment the customers. This is because unsupervised learning algorithms, such as k-means clustering or hierarchical clustering, can help identify natural groupings or clusters of customers without any prior knowledge of the number of profiles or segments. Additionally, using unsupervised learning algorithms can help identify patterns or structures in the data that may not be immediately apparent, which can lead to new insights and discoveries.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(user_input=\"So, based on your previous answer, which one from the 4 given sentences would you choose?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.Models.stop(\"togethercomputer/llama-2-70b-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
